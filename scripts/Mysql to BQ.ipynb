{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4800071e-49a8-4ab2-98c7-1fc3871a336a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mysql-connector-python in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (9.3.0)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: pandas-gbq in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (0.28.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (from pandas) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/diazprasetyo/.local/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (from pandas-gbq) (78.1.1)\n",
      "Requirement already satisfied: db-dtypes<2.0.0,>=1.0.4 in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (from pandas-gbq) (1.4.2)\n",
      "Requirement already satisfied: pyarrow>=4.0.0 in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (from pandas-gbq) (20.0.0)\n",
      "Requirement already satisfied: pydata-google-auth>=1.5.0 in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (from pandas-gbq) (1.9.1)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=2.10.2 in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (from pandas-gbq) (2.25.0rc0)\n",
      "Requirement already satisfied: google-auth>=2.13.0 in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (from pandas-gbq) (2.39.0)\n",
      "Requirement already satisfied: google-auth-oauthlib>=0.7.0 in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (from pandas-gbq) (1.2.2)\n",
      "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=3.4.2 in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (from pandas-gbq) (3.31.0)\n",
      "Requirement already satisfied: packaging>=22.0.0 in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (from pandas-gbq) (24.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas-gbq) (1.70.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas-gbq) (5.29.4)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas-gbq) (1.26.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas-gbq) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (from google-auth>=2.13.0->pandas-gbq) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (from google-auth>=2.13.0->pandas-gbq) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (from google-auth>=2.13.0->pandas-gbq) (4.9.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (from google-cloud-bigquery<4.0.0dev,>=3.4.2->pandas-gbq) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (from google-cloud-bigquery<4.0.0dev,>=3.4.2->pandas-gbq) (2.7.2)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery<4.0.0dev,>=3.4.2->pandas-gbq) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery<4.0.0dev,>=3.4.2->pandas-gbq) (1.71.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (from google-resumable-media<3.0.0,>=2.0.0->google-cloud-bigquery<4.0.0dev,>=3.4.2->pandas-gbq) (1.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/diazprasetyo/.local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas-gbq) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas-gbq) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas-gbq) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas-gbq) (2025.4.26)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (from rsa<5,>=3.1.4->google-auth>=2.13.0->pandas-gbq) (0.6.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (from google-auth-oauthlib>=0.7.0->pandas-gbq) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/anaconda3/envs/dbt_analytics/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.7.0->pandas-gbq) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mysql-connector-python pandas pandas-gbq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b429e572-0dde-4fd5-b5d5-af9aace2ab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector as connection\n",
    "import pandas as pd\n",
    "\n",
    "def data_pipeline_mysql_to_bq(**kwargs):\n",
    "\n",
    "    mysql_host = kwargs.get('mysql_host')\n",
    "    mysql_database = kwargs.get('mysql_database')\n",
    "    mysql_user = kwargs.get('mysql_user')\n",
    "    mysql_password = kwargs.get('mysql_password')\n",
    "    bq_project_id = kwargs.get('bq_project_id')\n",
    "    dataset = kwargs.get('dataset')\n",
    "\n",
    "    try:\n",
    "        mydb = connection.connect(host=mysql_host\\\n",
    "                                , database = mysql_database\\\n",
    "                                , user=mysql_user\\\n",
    "                                , passwd=mysql_password\\\n",
    "                                ,use_pure=True)\n",
    "\n",
    "        all_tables = \"Select table_name from information_schema.tables where table_schema = '{}'\".format(mysql_database)\n",
    "        df_tables = pd.read_sql(all_tables,mydb,\n",
    "                   parse_dates={'Date': {'format': '%Y-%m-%d'}})\n",
    "\n",
    "        for table in df_tables.TABLE_NAME:\n",
    "            table_name = table\n",
    "\n",
    "            # Extract table data from MySQL\n",
    "            df_table_data = extract_table_from_mysql(table_name, mydb)\n",
    "\n",
    "            # Transform table data from MySQL\n",
    "            df_table_data = transform_data_from_table(df_table_data)\n",
    "\n",
    "            # Load data to BigQuery\n",
    "            load_data_into_bigquery(bq_project_id,\n",
    "                                  dataset,table_name,df_table_data)\n",
    "\n",
    "            # Show confirmation message\n",
    "            print(\"Ingested table {}\".format(table_name))\n",
    "\n",
    "        mydb.close() #close the connection\n",
    "    except Exception as e:\n",
    "        mydb.close()\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c857b3f7-80b2-4675-b11b-a06845fa079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Simulate the extraction step in an ETL job\n",
    "'''\n",
    "def extract_table_from_mysql(table_name, my_sql_connection):\n",
    "    # Extract data from mysql table\n",
    "    extraction_query = 'select * from ' + table_name\n",
    "    df_table_data = pd.read_sql(extraction_query,my_sql_connection)\n",
    "    return df_table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97f33fb8-2549-4b04-a648-76e328997d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Simulate the transformation step in an ETL job\n",
    "'''\n",
    "def transform_data_from_table(df_table_data):\n",
    "    # Clean dates - convert to string\n",
    "    object_cols = df_table_data.select_dtypes(include=['object']).columns\n",
    "    for column in object_cols:\n",
    "        dtype = str(type(df_table_data[column].values[0]))\n",
    "        if dtype == \"<class 'datetime.date'>\":\n",
    "            df_table_data[column] = df_table_data[column].map(lambda x: str(x))\n",
    "    return df_table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5da43af-0c14-4a84-ad0e-c7b2901fe4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Simulate the load step in an ETL job\n",
    "'''\n",
    "def load_data_into_bigquery(bq_project_id, dataset,table_name,df_table_data):\n",
    "    import pandas_gbq as pdbq\n",
    "    full_table_name_bg = \"{}.{}\".format(dataset,table_name)\n",
    "    pdbq.to_gbq(df_table_data,full_table_name_bg,project_id=bq_project_id,\n",
    "      if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d079be97-b130-4ae0-9385-dd166d492292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zn/9zj33nn52b340ftt95qd_tqc0000gn/T/ipykernel_94564/370791738.py:21: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_tables = pd.read_sql(all_tables,mydb,\n",
      "/var/folders/zn/9zj33nn52b340ftt95qd_tqc0000gn/T/ipykernel_94564/2131377065.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_table_data = pd.read_sql(extraction_query,my_sql_connection)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingested table channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zn/9zj33nn52b340ftt95qd_tqc0000gn/T/ipykernel_94564/2131377065.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_table_data = pd.read_sql(extraction_query,my_sql_connection)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingested table customers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zn/9zj33nn52b340ftt95qd_tqc0000gn/T/ipykernel_94564/2131377065.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_table_data = pd.read_sql(extraction_query,my_sql_connection)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingested table products\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zn/9zj33nn52b340ftt95qd_tqc0000gn/T/ipykernel_94564/2131377065.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_table_data = pd.read_sql(extraction_query,my_sql_connection)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingested table purchaseHistory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zn/9zj33nn52b340ftt95qd_tqc0000gn/T/ipykernel_94564/2131377065.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_table_data = pd.read_sql(extraction_query,my_sql_connection)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingested table visitHistory\n"
     ]
    }
   ],
   "source": [
    "# Call main function\n",
    "\n",
    "kwargs = {\n",
    "    # BigQuery connection details\n",
    "    'bq_project_id': 'dbt-analytics-engineer-458723',\n",
    "    'dataset': 'omnichannel_raw',\n",
    "    # MySQL connection details\n",
    "    'mysql_host': 'localhost',\n",
    "    'mysql_user': 'root',\n",
    "    'mysql_password': 'efishery01',\n",
    "    'mysql_database': 'OMNI_MANAGEMENT'\n",
    "}\n",
    "\n",
    "data_pipeline_mysql_to_bq(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9166504e-9bb7-483e-8335-bbee283bf60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHECK MYSQL local connection\n",
    "\n",
    "# import mysql.connector as connection\n",
    "# import pandas as pd\n",
    "\n",
    "# def data_pipeline_mysql_to_bq(**kwargs):\n",
    "#     mysql_host = kwargs.get('mysql_host')\n",
    "#     mysql_database = kwargs.get('mysql_database')\n",
    "#     mysql_user = kwargs.get('mysql_user')\n",
    "#     mysql_password = kwargs.get('mysql_password')\n",
    "#     bq_project_id = kwargs.get('bq_project_id')\n",
    "#     dataset = kwargs.get('dataset')\n",
    "\n",
    "#     try:\n",
    "#         print(\"Connecting to MySQL database...\")\n",
    "#         mydb = connection.connect(host=mysql_host,\n",
    "#                                 database=mysql_database,\n",
    "#                                 user=mysql_user,\n",
    "#                                 passwd=mysql_password,\n",
    "#                                 use_pure=True)\n",
    "#         print(\"Connected successfully!\")\n",
    "\n",
    "#         all_tables = \"Select table_name from information_schema.tables where table_schema = '{}'\".format(mysql_database)\n",
    "#         print(f\"Executing query: {all_tables}\")\n",
    "        \n",
    "#         df_tables = pd.read_sql(all_tables, mydb, \n",
    "#                              parse_dates={'Date': {'format': '%Y-%m-%d'}})\n",
    "        \n",
    "#         # Add diagnostic information\n",
    "#         print(\"Tables found:\", df_tables.shape[0])\n",
    "#         print(\"Column names:\", df_tables.columns.tolist())\n",
    "        \n",
    "#         # Check if the DataFrame has any rows\n",
    "#         if df_tables.empty:\n",
    "#             print(\"No tables found in the database\")\n",
    "#             mydb.close()\n",
    "#             return\n",
    "            \n",
    "#         # Determine the correct column name\n",
    "#         table_column = None\n",
    "#         if 'table_name' in df_tables.columns:\n",
    "#             table_column = 'table_name'\n",
    "#             print(\"Using column 'table_name'\")\n",
    "#         elif 'TABLE_NAME' in df_tables.columns:\n",
    "#             table_column = 'TABLE_NAME'\n",
    "#             print(\"Using column 'TABLE_NAME'\")\n",
    "#         else:\n",
    "#             print(\"Unable to find table name column. Available columns:\", df_tables.columns.tolist())\n",
    "#             mydb.close()\n",
    "#             return\n",
    "        \n",
    "#         # Print first few tables for verification\n",
    "#         print(\"First few tables:\", df_tables[table_column].head().tolist())\n",
    "\n",
    "#         for table in df_tables[table_column]:\n",
    "#             table_name = table\n",
    "#             print(f\"\\nProcessing table: {table_name}\")\n",
    "\n",
    "#             # Extract table data from MySQL\n",
    "#             df_table_data = extract_table_from_mysql(table_name, mydb)\n",
    "            \n",
    "#             # Add diagnostic info for the table data\n",
    "#             print(f\"Extracted data shape: {df_table_data.shape}\")\n",
    "#             if df_table_data.empty:\n",
    "#                 print(f\"Table {table_name} is empty, skipping\")\n",
    "#                 continue\n",
    "\n",
    "#             # Transform table data from MySQL\n",
    "#             df_table_data = transform_data_from_table(df_table_data)\n",
    "\n",
    "#             # Load data to BigQuery\n",
    "#             load_data_into_bigquery(bq_project_id, dataset, table_name, df_table_data)\n",
    "\n",
    "#             # Show confirmation message\n",
    "#             print(\"Ingested table {}\".format(table_name))\n",
    "\n",
    "#         mydb.close()  # close the connection\n",
    "#         print(\"MySQL connection closed.\")\n",
    "#     except Exception as e:\n",
    "#         if 'mydb' in locals() and mydb.is_connected():\n",
    "#             mydb.close()\n",
    "#             print(\"MySQL connection closed due to error.\")\n",
    "#         print(\"Error:\", str(e))\n",
    "\n",
    "\n",
    "# def extract_table_from_mysql(table_name, my_sql_connection):\n",
    "#     # Extract data from mysql table\n",
    "#     print(f\"Extracting data from table: {table_name}\")\n",
    "#     extraction_query = 'select * from ' + table_name\n",
    "#     try:\n",
    "#         df_table_data = pd.read_sql(extraction_query, my_sql_connection)\n",
    "#         return df_table_data\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error extracting table {table_name}: {str(e)}\")\n",
    "#         return pd.DataFrame()  # Return empty DataFrame on error\n",
    "\n",
    "\n",
    "# def transform_data_from_table(df_table_data):\n",
    "#     # Clean dates - convert to string\n",
    "#     print(\"Transforming data...\")\n",
    "#     try:\n",
    "#         object_cols = df_table_data.select_dtypes(include=['object']).columns\n",
    "#         print(f\"Object columns to process: {len(object_cols)}\")\n",
    "        \n",
    "#         for column in object_cols:\n",
    "#             # Skip empty columns\n",
    "#             if df_table_data[column].empty:\n",
    "#                 print(f\"Column {column} is empty, skipping\")\n",
    "#                 continue\n",
    "                \n",
    "#             # Check if the column has any non-null values\n",
    "#             non_null_values = df_table_data[column].dropna()\n",
    "#             if len(non_null_values) == 0:\n",
    "#                 print(f\"Column {column} has only null values, skipping\")\n",
    "#                 continue\n",
    "                \n",
    "#             # Safely get the first non-null value\n",
    "#             first_value = non_null_values.iloc[0]\n",
    "#             dtype = str(type(first_value))\n",
    "#             print(f\"Column {column}, first value type: {dtype}\")\n",
    "            \n",
    "#             if dtype == \"<class 'datetime.date'>\":\n",
    "#                 print(f\"Converting column {column} from date to string\")\n",
    "#                 df_table_data[column] = df_table_data[column].map(lambda x: str(x) if x is not None else None)\n",
    "                \n",
    "#         return df_table_data\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error in transform: {str(e)}\")\n",
    "#         return df_table_data  # Return the original DataFrame if there's an error\n",
    "\n",
    "\n",
    "# def load_data_into_bigquery(bq_project_id, dataset, table_name, df_table_data):\n",
    "#     # Load data to BigQuery\n",
    "#     print(f\"Loading data to BigQuery: {dataset}.{table_name}\")\n",
    "#     try:\n",
    "#         import pandas_gbq as pdbq\n",
    "#         full_table_name_bg = \"{}.{}\".format(dataset, table_name)\n",
    "#         pdbq.to_gbq(df_table_data, full_table_name_bg, project_id=bq_project_id, if_exists='replace')\n",
    "#         print(f\"Loaded {len(df_table_data)} rows to BigQuery\")\n",
    "#         return True\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error loading to BigQuery: {str(e)}\")\n",
    "#         return False\n",
    "\n",
    "\n",
    "# # Call main function\n",
    "# if __name__ == \"__main__\":\n",
    "#     kwargs = {\n",
    "#         # BigQuery connection details\n",
    "#         'bq_project_id': 'dbt-analytics-engineer-458723',\n",
    "#         'dataset': 'omnichannel_raw',\n",
    "#         # MySQL connection details\n",
    "#         'mysql_host': 'localhost',\n",
    "#         'mysql_user': 'root',\n",
    "#         'mysql_password': 'efishery01',\n",
    "#         'mysql_database': 'OMNI_MANAGEMENT'\n",
    "#     }\n",
    "    \n",
    "#     data_pipeline_mysql_to_bq(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167b3be9-0e36-4a06-a94d-c426c3fcfc7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
